{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeGrad vs Conditional TimeGrad Comparison\n",
    "\n",
    "This notebook trains a lightweight vanilla TimeGrad model and a conditioning-aware TimeGrad variant on the same data, then visualizes their forecasts side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The imports assume this notebook lives in `notebooks/` under the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "try:\n",
    "    project_root = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    project_root = Path(os.getcwd()).resolve().parent\n",
    "\n",
    "if str(project_root) not in os.sys.path:\n",
    "    os.sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data_loader import TimeGradDataModule\n",
    "from src.models.timegrad_core.timegrad_base import TimeGradBase\n",
    "from src.predictor import ConditionalTimeGradPredictionNetwork\n",
    "from src.training import ConditionalTimeGradTrainingNetwork\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51570636",
   "metadata": {},
   "source": [
    "## Load & preprocess data\n",
    "This matches the preprocessing flow used in the conditional demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e42506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = project_root / 'data'\n",
    "raw_base = data_base / 'raw'\n",
    "\n",
    "raw_paths = {\n",
    "    'target': raw_base / 'target.parquet',\n",
    "    'market': raw_base / 'market.parquet',\n",
    "    'daily_macro': raw_base / 'daily_macro.parquet',\n",
    "    'monthly_macro': raw_base / 'monthly_macro.parquet',\n",
    "    'quarterly_macro': raw_base / 'quarterly_macro.parquet',\n",
    "}\n",
    "data_dict = {name: pd.read_parquet(path) for name, path in raw_paths.items()}\n",
    "print({k: v.shape for k, v in data_dict.items()})\n",
    "\n",
    "context_length = 64\n",
    "prediction_length = 24\n",
    "batch_size = 4\n",
    "\n",
    "dm = TimeGradDataModule(\n",
    "    data_dict=data_dict,\n",
    "    seq_len=context_length,\n",
    "    forecast_horizon=prediction_length,\n",
    "    batch_size=batch_size,\n",
    "    device=str(device),\n",
    ")\n",
    "dm.preprocess_and_split()\n",
    "dm.build_datasets()\n",
    "\n",
    "feature_cols = dm.get_feature_columns_by_type()\n",
    "feature_cols['cond_dynamic'] = feature_cols['daily'] + feature_cols['monthly']\n",
    "feature_cols['cond_static'] = feature_cols['regime']\n",
    "\n",
    "print('Feature columns by type:')\n",
    "for k, v in feature_cols.items():\n",
    "    print(f\"  {k}: {len(v)} cols\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a47c6d",
   "metadata": {},
   "source": [
    "## Minimal vanilla TimeGrad wrapper\n",
    "The helper below mirrors the conditional wrapper's normalization but omits conditioning. It allows quick training and sampling for the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaTimeGradWrapper(nn.Module):\n",
    "    def __init__(self, target_dim: int, prediction_length: int, scale_eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.prediction_length = prediction_length\n",
    "        self.scale_eps = scale_eps\n",
    "        self.model = TimeGradBase(target_dim=target_dim, prediction_length=prediction_length)\n",
    "\n",
    "    def _normalize(self, x_hist: torch.Tensor, x_future: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        combined = torch.cat([x_hist, x_future], dim=1)\n",
    "        loc = combined.mean(dim=1, keepdim=True)\n",
    "        scale = combined.std(dim=1, keepdim=True).clamp_min(self.scale_eps)\n",
    "        return loc, scale, (x_future - loc) / scale\n",
    "\n",
    "    def forward(self, x_hist: torch.Tensor, x_future: torch.Tensor) -> torch.Tensor:\n",
    "        loc, scale, x_future_norm = self._normalize(x_hist, x_future)\n",
    "        loss = self.model(x_future_norm)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, x_hist: torch.Tensor, num_samples: int = 100) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        loc = x_hist.mean(dim=1, keepdim=True)\n",
    "        scale = x_hist.std(dim=1, keepdim=True).clamp_min(self.scale_eps)\n",
    "\n",
    "        samples = [\n",
    "            self.model.diffusion.sample(\n",
    "                batch_size=x_hist.shape[0],\n",
    "                horizon=self.prediction_length,\n",
    "            ).transpose(1, 2) * scale\n",
    "            + loc\n",
    "            for _ in range(num_samples)\n",
    "        ]\n",
    "        stacked = torch.stack(samples, dim=0)  # [S, B, horizon, C]\n",
    "        return stacked, loc.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdea804",
   "metadata": {},
   "source": [
    "## Train both models (small demo epochs)\n",
    "Training loops keep epochs small for a quick comparison; increase them for higher fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc55a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla = VanillaTimeGradWrapper(target_dim=len(feature_cols['target']), prediction_length=prediction_length).to(device)\n",
    "conditional_train = ConditionalTimeGradTrainingNetwork(\n",
    "    target_dim=len(feature_cols['target']),\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    cond_dynamic_dim=len(feature_cols['cond_dynamic']),\n",
    "    cond_static_dim=len(feature_cols['cond_static']),\n",
    ").to(device)\n",
    "\n",
    "vanilla_opt = torch.optim.Adam(vanilla.parameters(), lr=1e-3)\n",
    "conditional_opt = torch.optim.Adam(conditional_train.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    vanilla.train(); conditional_train.train()\n",
    "    for batch in DataLoader(dm.train_set, batch_size=batch_size, shuffle=True):\n",
    "        x_hist = batch['x_hist'].to(device)\n",
    "        x_future = batch['x_future'].to(device)\n",
    "        cond_dynamic = batch['cond_dynamic'].to(device)\n",
    "        cond_static = batch['cond_static'].to(device)\n",
    "\n",
    "        vanilla_opt.zero_grad()\n",
    "        vanilla_loss = vanilla(x_hist, x_future).mean()\n",
    "        vanilla_loss.backward()\n",
    "        vanilla_opt.step()\n",
    "\n",
    "        conditional_opt.zero_grad()\n",
    "        cond_loss = conditional_train(x_hist, x_future, cond_dynamic, cond_static)\n",
    "        cond_loss.backward()\n",
    "        conditional_opt.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec6076",
   "metadata": {},
   "source": [
    "## Build conditional predictor for sampling\n",
    "The predictor reuses the trained conditional backbone and supports masked or full-horizon sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_pred = ConditionalTimeGradPredictionNetwork(\n",
    "    target_dim=len(feature_cols['target']),\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    cond_dynamic_dim=len(feature_cols['cond_dynamic']),\n",
    "    cond_static_dim=len(feature_cols['cond_static']),\n",
    ").to(device)\n",
    "conditional_pred.model.load_state_dict(conditional_train.model.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd1c554",
   "metadata": {},
   "source": [
    "## Compare forecasts on a held-out batch\n",
    "We draw a batch from the test split, generate multiple samples from each model, and plot their mean forecasts against the ground truth target window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(dm.test_dataloader()))\n",
    "x_hist = test_batch['x_hist'].to(device)\n",
    "x_future = test_batch['x_future'].to(device)\n",
    "cond_dynamic = test_batch['cond_dynamic'].to(device)\n",
    "cond_static = test_batch['cond_static'].to(device)\n",
    "\n",
    "# Vanilla samples\n",
    "vanilla.eval()\n",
    "vanilla_samples, _ = vanilla.sample(x_hist, num_samples=200)\n",
    "vanilla_mean = vanilla_samples.mean(dim=0).detach().cpu().numpy()[0]\n",
    "\n",
    "# Conditional samples\n",
    "conditional_pred.eval()\n",
    "cond_samples = conditional_pred.sample_autoregressive(\n",
    "    x_hist=x_hist,\n",
    "    cond_dynamic=cond_dynamic,\n",
    "    cond_static=cond_static,\n",
    "    num_samples=200,\n",
    "    sampling_strategy='masked_step',\n",
    ")\n",
    "cond_mean = cond_samples.mean(dim=0).detach().cpu().numpy()[0]\n",
    "\n",
    "truth = x_future[0].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_crps(samples: torch.Tensor, target: torch.Tensor) -> float:\n",
    "    # samples: [S, B, T, D], target: [B, T, D]\n",
    "    s1 = (samples - target).abs().mean(dim=0)\n",
    "    s2 = (samples.unsqueeze(0) - samples.unsqueeze(1)).abs().mean(dim=(0, 1))\n",
    "    return (s1 - 0.5 * s2).mean().item()\n",
    "\n",
    "vanilla_crps = sample_crps(vanilla_samples, x_future)\n",
    "cond_crps = sample_crps(cond_samples, x_future)\n",
    "print(f'CRPS (vanilla TimeGrad): {vanilla_crps:.4f}')\n",
    "print(f'CRPS (conditional TimeGrad): {cond_crps:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b07afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(truth[:, 0], label='Ground truth', linewidth=2)\n",
    "plt.plot(vanilla_mean[:, 0], label='Vanilla TimeGrad mean')\n",
    "plt.plot(cond_mean[:, 0], label='Conditional TimeGrad mean')\n",
    "plt.xlabel('Horizon step')\n",
    "plt.ylabel('Target value')\n",
    "plt.title('Forecast comparison')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
